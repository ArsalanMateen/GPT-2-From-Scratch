A 124M parameter foundation model (similar scale to GPT-2 Small) architected from scratch using PyTorch.

Want to try it out? Click [here](https://huggingface.co/spaces/arsalanmateen/PersonalGPT) 

![](./interface.png)